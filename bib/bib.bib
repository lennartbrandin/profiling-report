
@article{graham_gprof_1982,
	title = {Gprof: A call graph execution profiler},
	volume = {17},
	issn = {0362-1340, 1558-1160},
	url = {https://dl.acm.org/doi/10.1145/872726.806987},
	doi = {10.1145/872726.806987},
	shorttitle = {Gprof},
	abstract = {Large complex programs are composed of many small routines that implement abstractions for the routines that call them. To be useful, an execution profiler must attribute execution time in a way that is significant for the logical structure of a program as well as for its textual decomposition. This data must then be displayed to the user in a convenient and informative way. The
              gprof
              profiler accounts for the running time of called routines in the running time of the routines that call them. The design and use of this profiler is described.},
	pages = {120--126},
	number = {6},
	journaltitle = {{ACM} {SIGPLAN} Notices},
	shortjournal = {{SIGPLAN} Not.},
	author = {Graham, Susan L. and Kessler, Peter B. and Mckusick, Marshall K.},
	urldate = {2025-05-11},
	date = {1982-06},
	langid = {english},
}

@article{wood_survey_nodate,
	title = {A Survey of Performance Analysis Tools},
	url = {https://www.cse.wustl.edu/~jain/cse567-06/ftp/perf_tools/index.html},
	abstract = {In this paper, we present a survey of various tools that can be used to aid in performance analysis of computer software programs. We present and discuss different techniques in emerging performance analysis tools as well as provide examples of each type of method. For example, we will cover simple techniques such as timer routines with manual instrumentation to statistical profiling tools and more advanced dynamic instrumentation techniques, in which code can be monitored and changed on the fly. Additionally, a brief comparison of the tools will be presented with some tradeoff considerations.},
	author = {Wood, Patrick},
	langid = {english},
	file = {PDF:files/4/Wood - A Survey of Performance Analysis Tools.pdf:application/pdf},
}

@inproceedings{bernecky_profiling_1989,
	location = {New York, New York, United States},
	title = {Profiling, performance, and perfection (tutorial session)},
	isbn = {978-0-89791-331-7},
	url = {http://portal.acm.org/citation.cfm?doid=328877.328879},
	doi = {10.1145/328877.328879},
	eventtitle = {the {ACM}/{SIGAPL} conference},
	pages = {31--52},
	booktitle = {Proceedings of the {ACM}/{SIGAPL} conference on {APL} as a tool of thought (session tutorials)  -},
	publisher = {{ACM} Press},
	author = {Bernecky, Robert},
	urldate = {2025-05-11},
	date = {1989},
	langid = {english},
}

@article{hu_towards_2025,
	title = {Towards On-The-Fly Code Performance Profiling},
	issn = {1049-331X, 1557-7392},
	url = {https://dl.acm.org/doi/10.1145/3725212},
	doi = {10.1145/3725212},
	abstract = {Improving the performance of software applications is one of the most important tasks in software evolution and maintenance. In the Intel Microarchitecture, {CPUs} employ pipelining to utilize resources as effectively as possible. Some types of software patterns or algorithms can have implications on the underlying {CPU} pipelines and result in inefficiencies. Therefore, analyzing how well the {CPU}’s pipeline(s) are being utilized while running an application is important in software performance analysis. Existing techniques, such as Intel {VTune} Profiler, usually detect software performance issues from {CPU} pipeline metrics after the software enters production and during the running time. These techniques require developers to manually analyze monitoring data and perform additional test runs to obtain relevant information about performance problems. It costs a lot of time and human effort for developers to build, deploy, test, execute, and monitor the software. To alleviate these problems, we propose a novel approach named {PGProf} to predict the {CPU} pipeline before execution and provide the profiling feedback during the development process. {PGProf} exploits the graph neural networks to learn semantic and structural representations for C functions and then predict the fraction of pipeline slots in each category for them during the development process. Given a code snippet, we fuse different types of code structures, e.g., Abstract Syntax Tree ({AST}), Data Flow Graph ({DFG}), and Control Flow Graph ({CFG}) into one program graph. During offline learning, we first leverage the gated graph neural network to capture representations of C functions. {PGProf} then automatically estimates the final pipeline values according to the learned semantic and structural features. For online prediction, we predict pipeline metrics with four category values by leveraging the offline trained model. We build our dataset from C projects in {GitHub} and use Intel {VTune} profiler to get profiling information by running them. Extensive experimental results show the promising performance of our model. We achieved absolute result of 49.90\% and 79.44\% in terms of 퐴푐푐@5\% and 퐴푐푐@10\% with improvements of 8.0\%-42.7\% and 7.8\%-20.1\% over a set of baselines.},
	pages = {3725212},
	journaltitle = {{ACM} Transactions on Software Engineering and Methodology},
	shortjournal = {{ACM} Trans. Softw. Eng. Methodol.},
	author = {Hu, Xing and Lin, Weixin and Liu, Zhuang and Xia, Xin and Ling, Michael and Wang, Yuan and Lo, David},
	urldate = {2025-05-12},
	date = {2025-03-26},
	langid = {english},
	file = {PDF:files/10/Hu et al. - 2025 - Towards On-The-Fly Code Performance Profiling.pdf:application/pdf},
}

@inproceedings{xu_can_2019,
	location = {Phoenix Arizona},
	title = {Can we trust profiling results?: understanding and fixing the inaccuracy in modern profilers},
	isbn = {978-1-4503-6079-1},
	url = {https://dl.acm.org/doi/10.1145/3330345.3330371},
	doi = {10.1145/3330345.3330371},
	shorttitle = {Can we trust profiling results?},
	eventtitle = {{ICS} '19: 2019 International Conference on Supercomputing},
	pages = {284--295},
	booktitle = {Proceedings of the {ACM} International Conference on Supercomputing},
	publisher = {{ACM}},
	author = {Xu, Hao and Wang, Qingsen and Song, Shuang and John, Lizy Kurian and Liu, Xu},
	urldate = {2025-05-12},
	date = {2019-06-26},
	langid = {english},
}

@article{gregg_flame_2016,
	title = {The flame graph},
	volume = {59},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/2909476},
	doi = {10.1145/2909476},
	abstract = {This visualization of software execution is a new necessity for performance profiling and debugging.},
	pages = {48--57},
	number = {6},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Gregg, Brendan},
	urldate = {2025-05-16},
	date = {2016-05-23},
	langid = {english},
}

@inproceedings{yasin_top-down_2014,
	location = {{CA}, {USA}},
	title = {A Top-Down method for performance analysis and counters architecture},
	isbn = {978-1-4799-3606-9 978-1-4799-3604-5},
	url = {http://ieeexplore.ieee.org/document/6844459/},
	doi = {10.1109/ISPASS.2014.6844459},
	eventtitle = {2014 {IEEE} International Symposium on Performance Analysis of Systems and Software ({ISPASS})},
	pages = {35--44},
	booktitle = {2014 {IEEE} International Symposium on Performance Analysis of Systems and Software ({ISPASS})},
	publisher = {{IEEE}},
	author = {Yasin, Ahmad},
	urldate = {2025-05-19},
	date = {2014-03},
}
